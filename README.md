# Perceptually Accurate 3D Talking Head Generation: New Definitions, Speech-Mesh Representation, and Evaluation Metrics 
<h3>CVPR 2025 <mark>Highlight</mark></h3>

### [Project Page](https://perceptual-3d-talking-head.github.io/) | [Paper](https://arxiv.org/pdf/2503.20308)

![Image](https://github.com/user-attachments/assets/90a114a5-5bc0-49dc-bb3b-b069784e4328)

<div align="center">
We define three criteria to assess perceptual alignment between speech and lip movements of 3D talking heads: <br>
Temporal Synchronization, Lip Readability, and Expressiveness.
</div>
<br>

This repository includes **speech-mesh synchronized representation** and their usage as **a perceptual loss**. 
We also provide **the evaluation codes for three metrics**â€”MTM, PLRS, and SLCCâ€”to assess how well the generated 3D talking heads align with the three criteria.

## ðŸ“š Citation
If you found this code useful, please consider citing our paper.

```
@article{chae2025perceptually,
  title={Perceptually Accurate 3D Talking Head Generation: New Definitions, Speech-Mesh Representation, and Evaluation Metrics},
  author={Chae-Yeon, Lee and Hyun-Bin, Oh and EunGi, Han and Sung-Bin, Kim and Nam, Suekyeong and Oh, Tae-Hyun},
  journal={arXiv preprint arXiv:2503.20308},
  year={2025}
}
```
